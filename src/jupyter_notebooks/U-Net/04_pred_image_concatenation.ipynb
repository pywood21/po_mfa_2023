{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023/03/03<br>\n",
    "This code is for concatenating images after prediction by UNet.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path\n",
    "current_path=os.getcwd()\n",
    "npz_path=os.path.join(current_path, \"npz_file\")\n",
    "pred_im_path=os.path.join(npz_path, \"pred_im\")\n",
    "pred_im_conc_path=os.path.join(npz_path, \"pred_im_concatenation\")\n",
    "fig_save_path=os.path.join(current_path, \"fig_save\", \"pred_concatenation\")\n",
    "\n",
    "for path in [pred_im_path, fig_save_path]:\n",
    "    if os.path.exists(path)==False:\n",
    "        os.makedirs(path)\n",
    "\n",
    "im_size=512\n",
    "im_step=256\n",
    "\n",
    "#find target files\n",
    "target_files=[]\n",
    "for curdir, _, files in os.walk(pred_im_path):\n",
    "    if len(files)>0:\n",
    "        for file in files:\n",
    "            target_file=os.path.join(curdir, file)\n",
    "            target_files.append(target_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load all images and concatenate them species by species "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [09:26<00:00, 16.35s/it]\n"
     ]
    }
   ],
   "source": [
    "for target_file in tqdm(target_files):\n",
    "    #load npz\n",
    "    npz=np.load(target_file, allow_pickle=True)\n",
    "    pred_im=npz[\"pred_im\"]\n",
    "    ori_im=npz[\"ori_im\"]\n",
    "    angle_im=npz[\"angle_im\"]\n",
    "    height_num=np.int(npz[\"height_num\"])\n",
    "    width_num=np.int(npz[\"width_num\"])\n",
    "    \n",
    "    #set matrices\n",
    "    result_mat=np.zeros((im_step*height_num+im_size, im_step*width_num+im_size))\n",
    "    MFA_ori_mat=np.zeros((im_step*height_num+im_size, im_step*width_num+im_size))\n",
    "    angle_mat=np.zeros((im_step*height_num+im_size, im_step*width_num+im_size))\n",
    "    div_mat=np.zeros((im_step*height_num+im_size, im_step*width_num+im_size))\n",
    "    \n",
    "    kernel=np.ones((im_size, im_size))\n",
    "    for i in range(len(pred_im)):\n",
    "        q, r = divmod(i, width_num+1)\n",
    "        result_mat[q*im_step:q*im_step+im_size, \n",
    "                   r*im_step:r*im_step+im_size]+=pred_im[i][:, :, 0]\n",
    "        div_mat[q*im_step:q*im_step+im_size, \n",
    "                   r*im_step:r*im_step+im_size]+=kernel\n",
    "        MFA_ori_mat[q*im_step:q*im_step+im_size, \n",
    "                   r*im_step:r*im_step+im_size]+=ori_im[i]\n",
    "        angle_mat[q*im_step:q*im_step+im_size, \n",
    "                   r*im_step:r*im_step+im_size]+=angle_im[i]\n",
    "    \n",
    "    #normalize results\n",
    "    result_mat=result_mat/div_mat\n",
    "    MFA_ori_mat=MFA_ori_mat/div_mat\n",
    "    angle_mat=angle_mat/div_mat\n",
    "    MFA_vis_mat= ((MFA_ori_mat-np.min(MFA_ori_mat))/(np.max(MFA_ori_mat)-np.min(MFA_ori_mat)))*255\n",
    "    \n",
    "    #binarization\n",
    "    thres=threshold_otsu(result_mat)\n",
    "    pred_binary=np.uint8((result_mat>thres)*255)\n",
    "    \n",
    "    #save result as npz\n",
    "    sample_name=os.path.splitext(os.path.basename(target_file))[0]\n",
    "    np.savez_compressed(os.path.join(pred_im_conc_path, sample_name+\".npz\"), \n",
    "                       MFA=MFA_ori_mat, angle=angle_mat, pred=result_mat, pred_binary=pred_binary)\n",
    "    \n",
    "    #save images as figure\n",
    "    target_save_path=os.path.join(fig_save_path, sample_name)\n",
    "    if os.path.exists(target_save_path)==False:\n",
    "        os.makedirs(target_save_path)\n",
    "    \n",
    "    #convert boundary image to transparent one for png\n",
    "    boundary_image_tr=np.zeros((pred_binary.shape[0], pred_binary.shape[1], 4), np.uint8)\n",
    "    boundary_image_tr[:,:,2]=pred_binary\n",
    "    boundary_image_tr[:,:,3] =np.where(np.all(boundary_image_tr == 0, axis=-1), 0, 255) \n",
    "    cv2.imwrite(os.path.join(target_save_path, sample_name+\".png\"), boundary_image_tr)\n",
    "    cv2.imwrite(os.path.join(target_save_path, sample_name+\"_ori.png\"), MFA_vis_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YKDL",
   "language": "python",
   "name": "ykdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
